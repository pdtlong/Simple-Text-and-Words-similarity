{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\charl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\charl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUn it to download stopword\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import nltk, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#Đọc data\n",
    "train = pd.read_csv('./train.csv')\n",
    "\n",
    "# xóa các từ stopwords.\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "x_list = []\n",
    "y_list = []\n",
    "x_list = [w.lower() for w in train['description_x'] if w not in stop_words]\n",
    "y_list = [w.lower() for w in train['description_y'] if w not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description_x</th>\n",
       "      <th>description_y</th>\n",
       "      <th>ticker_x</th>\n",
       "      <th>ticker_y</th>\n",
       "      <th>same_security</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>first trust dow jones internet</td>\n",
       "      <td>first trust dj internet idx</td>\n",
       "      <td>FDN</td>\n",
       "      <td>FDN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>schwab intl large company index etf</td>\n",
       "      <td>schwab strategic tr fundamental intl large co ...</td>\n",
       "      <td>FNDF</td>\n",
       "      <td>FNDF</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>vanguard small cap index adm</td>\n",
       "      <td>vanguard small-cap index fund inst</td>\n",
       "      <td>VSMAX</td>\n",
       "      <td>VSCIX</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>duke energy corp new com new isin #us4 sedol #...</td>\n",
       "      <td>duke energy corp new com new isin #us26441c204...</td>\n",
       "      <td>DUK</td>\n",
       "      <td>DUK</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>visa inc class a</td>\n",
       "      <td>visa inc.</td>\n",
       "      <td>V</td>\n",
       "      <td>V</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                      description_x  \\\n",
       "0           0                     first trust dow jones internet   \n",
       "1           1                schwab intl large company index etf   \n",
       "2           2                       vanguard small cap index adm   \n",
       "3           3  duke energy corp new com new isin #us4 sedol #...   \n",
       "4           4                                   visa inc class a   \n",
       "\n",
       "                                       description_y ticker_x ticker_y  \\\n",
       "0                        first trust dj internet idx      FDN      FDN   \n",
       "1  schwab strategic tr fundamental intl large co ...     FNDF     FNDF   \n",
       "2                 vanguard small-cap index fund inst    VSMAX    VSCIX   \n",
       "3  duke energy corp new com new isin #us26441c204...      DUK      DUK   \n",
       "4                                          visa inc.        V        V   \n",
       "\n",
       "   same_security  \n",
       "0           True  \n",
       "1           True  \n",
       "2          False  \n",
       "3           True  \n",
       "4           True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set ['first trust dow jones internet', 'schwab intl large company index etf', 'vanguard small cap index adm', 'duke energy corp new com new isin #us4 sedol #b7jzsk0', 'visa inc class a', 'ford motor co new div: 0.600', 'united states steel corp', 'vanguard total international bond index etf', 'schwab strategic tr us sml c', 'mfs value fd cl i'] \n",
      "\n",
      "Test set ['first trust dj internet idx', 'schwab strategic tr fundamental intl large co index etf', 'vanguard small-cap index fund inst', 'duke energy corp new com new isin #us26441c2044 sedol #b7jzs', 'visa inc.', 'ford motor co', 'united sts stl cp (new)', 'vanguard total intl bond index etf', 'schwab us small cap etf', 'mfs value fund cl i']\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set\", x_list[0:10],\"\\n\")\n",
    "print(\"Test set\",y_list[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text similarity với one-hot và độ đo cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(A,B): \n",
    "    return (sum(a*b for a,b in zip(A,B)))\n",
    "def cosine_similarity_original(a,b):\n",
    "    return dot(a,b) / ( (dot(a,a) **.5) * (dot(b,b) ** .5) )\n",
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Text similarity với One hot vector và độ do cosine: -----\n",
      "Sentence x( 0 ): first trust dow jones internet -> [0 0 0 ... 0 0 0]\n",
      "Sentence y( 0 ): first trust dj internet idx -> [0 0 0 ... 0 0 0]\n",
      "=> cosine similarity 0.577 \n",
      "\n",
      "Sentence x( 1 ): schwab intl large company index etf -> [0 0 0 ... 0 0 0]\n",
      "Sentence y( 1 ): schwab strategic tr fundamental intl large co index etf -> [0 0 0 ... 0 0 0]\n",
      "=> cosine similarity 0.722 \n",
      "\n",
      "Sentence x( 2 ): vanguard small cap index adm -> [0 0 0 ... 0 0 0]\n",
      "Sentence y( 2 ): vanguard small-cap index fund inst -> [0 0 0 ... 0 0 0]\n",
      "=> cosine similarity 0.730 \n",
      "\n",
      "Sentence x( 3 ): duke energy corp new com new isin #us4 sedol #b7jzsk0 -> [0 0 0 ... 0 0 0]\n",
      "Sentence y( 3 ): duke energy corp new com new isin #us26441c2044 sedol #b7jzs -> [0 0 0 ... 0 0 0]\n",
      "=> cosine similarity 0.913 \n",
      "\n",
      "Sentence x( 4 ): visa inc class a -> [0 0 0 ... 0 0 0]\n",
      "Sentence y( 4 ): visa inc. -> [0 0 0 ... 0 0 0]\n",
      "=> cosine similarity 0.707 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gọi hàm stop word\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "#Khử stop word\n",
    "x_list_onehot = vectorizer.fit_transform(x_list).toarray()\n",
    "y_list_onehot = vectorizer.transform(y_list).toarray()\n",
    "\n",
    "print (\"-----Text similarity với One hot vector và độ do cosine: -----\")\n",
    "for i in range(5):\n",
    "    print (\"Sentence x(\",i,\"):\",x_list[i],\"->\",x_list_onehot[i])\n",
    "    print (\"Sentence y(\",i,\"):\",y_list[i],\"->\",y_list_onehot[i])\n",
    "    print (\"=> cosine similarity %.3f\" % cosine_similarity_original(x_list_onehot[i],y_list_onehot[i]),\"\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text similarity với TF-IDF và độ do cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Xóa Ký tự đặc biệt\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "#Áp dụng tf-idf và xóa stop word\n",
    "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
    "\n",
    "def cosine_similarity_TFIDF(text1, text2):\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence x( 0 ): first trust dow jones internet\n",
      "Sentence y( 0 ): first trust dj internet idx\n",
      "=> cosine similarity 0.336 \n",
      "\n",
      "Sentence x( 1 ): schwab intl large company index etf\n",
      "Sentence y( 1 ): schwab strategic tr fundamental intl large co index etf\n",
      "=> cosine similarity 0.573 \n",
      "\n",
      "Sentence x( 2 ): vanguard small cap index adm\n",
      "Sentence y( 2 ): vanguard small-cap index fund inst\n",
      "=> cosine similarity 0.252 \n",
      "\n",
      "Sentence x( 3 ): duke energy corp new com new isin #us4 sedol #b7jzsk0\n",
      "Sentence y( 3 ): duke energy corp new com new isin #us26441c2044 sedol #b7jzs\n",
      "=> cosine similarity 0.717 \n",
      "\n",
      "Sentence x( 4 ): visa inc class a\n",
      "Sentence y( 4 ): visa inc.\n",
      "=> cosine similarity 0.580 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print (\"Sentence x(\",i,\"):\",x_list[i])\n",
    "    print (\"Sentence y(\",i,\"):\",y_list[i])\n",
    "    print (\"=> cosine similarity %.3f\" %cosine_similarity_TFIDF(x_list[i],y_list[i]),\"\\n\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word similarity và Text Similarity với Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp37-cp37m-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\charl\\.conda\\envs\\py37\\lib\\site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\charl\\.conda\\envs\\py37\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-6.0.0-py3-none-any.whl (58 kB)\n",
      "Collecting Cython==0.29.28\n",
      "  Downloading Cython-0.29.28-py2.py3-none-any.whl (983 kB)\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "Successfully installed Cython-0.29.28 gensim-4.2.0 smart-open-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "# Import Data\n",
    "df=pd.read_csv('./questions.csv')\n",
    " \n",
    "# Check for null values\n",
    "df[df.isnull().any(axis=1)]\n",
    " \n",
    "# Drop rows with null Values\n",
    "df.drop(df[df.isnull().any(axis=1)].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>How can I convert raw files to JPEG in photos ...</td>\n",
       "      <td>How do you convert raw files to JPEG?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1001</td>\n",
       "      <td>2003</td>\n",
       "      <td>2004</td>\n",
       "      <td>What is the best age to teach a child how to s...</td>\n",
       "      <td>When is a good time to teach your children how...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>2005</td>\n",
       "      <td>2006</td>\n",
       "      <td>Which is less healthy for your body, beer or P...</td>\n",
       "      <td>Which is less healthy for your body light beer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>2007</td>\n",
       "      <td>2008</td>\n",
       "      <td>Where can I find my mentor?</td>\n",
       "      <td>Where can I find a willing mentor?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>2009</td>\n",
       "      <td>2010</td>\n",
       "      <td>What would cause an AMP to cut out?</td>\n",
       "      <td>What would cause an AMP to cut out? How do you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  qid1  qid2                                          question1  \\\n",
       "1000  1000  2001  2002  How can I convert raw files to JPEG in photos ...   \n",
       "1001  1001  2003  2004  What is the best age to teach a child how to s...   \n",
       "1002  1002  2005  2006  Which is less healthy for your body, beer or P...   \n",
       "1003  1003  2007  2008                        Where can I find my mentor?   \n",
       "1004  1004  2009  2010                What would cause an AMP to cut out?   \n",
       "\n",
       "                                              question2  is_duplicate  \n",
       "1000              How do you convert raw files to JPEG?             0  \n",
       "1001  When is a good time to teach your children how...             1  \n",
       "1002  Which is less healthy for your body light beer...             1  \n",
       "1003                 Where can I find a willing mentor?             0  \n",
       "1004  What would cause an AMP to cut out? How do you...             1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1000:1005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean texts và remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review):  \n",
    "    # Convert words to lower case and split them\n",
    "    words = review.lower().split()\n",
    "\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    words = [w for w in words if not w in stops]\n",
    "    \n",
    "    review_text = \" \".join(words)\n",
    "\n",
    "    # Clean the text\n",
    "    review_text = re.sub(r\"[^A-Za-z0-9(),!.?\\'\\`]\", \" \", review_text)\n",
    "    review_text = re.sub(r\"\\'s\", \" 's \", review_text)\n",
    "    review_text = re.sub(r\"\\'ve\", \" 've \", review_text)\n",
    "    review_text = re.sub(r\"n\\'t\", \" 't \", review_text)\n",
    "    review_text = re.sub(r\"\\'re\", \" 're \", review_text)\n",
    "    review_text = re.sub(r\"\\'d\", \" 'd \", review_text)\n",
    "    review_text = re.sub(r\"\\'ll\", \" 'll \", review_text)\n",
    "    review_text = re.sub(r\",\", \" \", review_text)\n",
    "    review_text = re.sub(r\"\\.\", \" \", review_text)\n",
    "    review_text = re.sub(r\"!\", \" \", review_text)\n",
    "    review_text = re.sub(r\"\\(\", \" ( \", review_text)\n",
    "    review_text = re.sub(r\"\\)\", \" ) \", review_text)\n",
    "    review_text = re.sub(r\"\\?\", \" \", review_text)\n",
    "    review_text = re.sub(r\"\\s{2,}\", \" \", review_text)\n",
    "    \n",
    "    words = review_text.split()\n",
    "    \n",
    "\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    review_text = \" \".join(stemmed_words)\n",
    "    \n",
    "    return(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_questions(question_list, questions, question_list_name):\n",
    "# function to transform questions and display progress\n",
    "    for question in questions:\n",
    "        question_list.append(review_to_wordlist(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "questions1 = []     \n",
    "process_questions(questions1, df.question1, \"questions1\")\n",
    "print()\n",
    "questions2 = []     \n",
    "process_questions(questions2, df.question2, \"questions2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['step step guid invest share market india', 'stori kohinoor ( koh i noor ) diamond', 'increas speed internet connect use vpn', 'mental lone solv it', 'one dissolv water quik sugar salt methan carbon di oxid']\n",
      "['step step guid invest share market', 'would happen indian govern stole kohinoor ( koh i noor ) diamond back', 'internet speed increas hack dns', 'find remaind math 23 24 math divid 24 23', 'fish would surviv salt water']\n"
     ]
    }
   ],
   "source": [
    "print(questions1[:5])\n",
    "print(questions2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng câu invalid 353\n"
     ]
    }
   ],
   "source": [
    "# Lưu các chỉ mục câu không xác định\n",
    "invalid_questions = []\n",
    "\n",
    "for i in range(len(questions1)):\n",
    "    # Câu hỏi cần chứa nguyên âm\n",
    "    if not re.search('[aeiouyAEIOUY]', questions1[i]) or not re.search('[aeiouyAEIOUY]', questions2[i]):\n",
    "    # Điều chính số câu sau khi xóa các chỉ mục sai\n",
    "        invalid_questions.append(i-len(invalid_questions))\n",
    "        \n",
    "print(\"Số lượng câu invalid\",len(invalid_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in invalid_questions:\n",
    "    df = df[df.id != index]\n",
    "    questions1.pop(index)\n",
    "    questions2.pop(index)\n",
    "    \n",
    "unexpected_invalid_questions = [36460,42273,65937,304867,306828,353918]\n",
    "\n",
    "for index in unexpected_invalid_questions:\n",
    "    df = df[df.id != index]\n",
    "    questions1.pop(index)\n",
    "    questions2.pop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% complete\n",
      "9.9% complete\n",
      "19.8% complete\n",
      "29.7% complete\n",
      "39.61% complete\n",
      "49.51% complete\n",
      "59.41% complete\n",
      "69.31% complete\n",
      "79.21% complete\n",
      "89.11% complete\n",
      "99.01% complete\n"
     ]
    }
   ],
   "source": [
    "# Contains the processed questions for Doc2Vec\n",
    "questions_labeled = []\n",
    "\n",
    "for i in range(len(questions1)):\n",
    "    # Question strings need to be separated into words\n",
    "    # Each question needs a unique label\n",
    "    questions_labeled.append(TaggedDocument(words=questions1[i].split(), tags=df[df.index == i].qid1))\n",
    "    questions_labeled.append(TaggedDocument(words=questions2[i].split(), tags=df[df.index == i].qid2))\n",
    "    if i % 40000 == 0:\n",
    "        progress = i/len(questions1) * 100\n",
    "        print(\"{}% complete\".format(round(progress, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split questions for computing similarity and determining the lengths of the questions.\n",
    "questions1_split = []\n",
    "for question in questions1:\n",
    "    questions1_split.append(question.split())\n",
    "    \n",
    "questions2_split = []\n",
    "for question in questions2:\n",
    "    questions2_split.append(question.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the length of questions to select more optimal parameters.\n",
    "lengths = []\n",
    "for i in range(len(questions1_split)):\n",
    "    lengths.append(len(questions1_split[i]))\n",
    "    lengths.append(len(questions2_split[i]))\n",
    "lengths = pd.DataFrame(lengths, columns=[\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Doc2Vec(dm = 1, min_count=1, window=10, vector_size=150, sample=1e-4, negative=10)\n",
    "model.build_vocab(questions_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(questions_labeled,total_examples=model.corpus_count,epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text similarity with Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_scores = []\n",
    "for i in range(len(questions1_split)):\n",
    "    # n_similarity computes the cosine similarity in Doc2Vec\n",
    "    score = model.docvecs.n_similarity(questions1_split[i],questions2_split[i])\n",
    "    doc2vec_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.hist(doc2vec_scores, bins = 200)\n",
    "plt.xlim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 63%.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "scores = []\n",
    "for score in doc2vec_scores:\n",
    "        if score >= 0.9:\n",
    "            scores.append(1)\n",
    "        else:\n",
    "            scores.append(0)\n",
    "            \n",
    "accuracy = accuracy_score(df.is_duplicate, scores) * 100\n",
    "print(\"Accuracy score is {}%.\".format(round(accuracy),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
